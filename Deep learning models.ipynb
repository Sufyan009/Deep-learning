{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b94222fd-35ef-47cc-bb15-d508c7c13f6c",
   "metadata": {},
   "source": [
    "\n",
    "| **Model**              | **Strengths**                                                                 | **Weaknesses**                                                         | **When to Use**                                      | **Improvements**                                                                                                   |\n",
    "|-------------------------|-------------------------------------------------------------------------------|------------------------------------------------------------------------|-----------------------------------------------------|--------------------------------------------------------------------------------------------------------------------|\n",
    "| **Perceptron (1958)**   | Simple, efficient for linearly separable data.                               | Cannot solve non-linear problems (e.g., XOR).                          | Basic linearly separable problems.                 | Multi-Layer Perceptron (MLP) introduced hidden layers for non-linear problems.                                    |\n",
    "| **MLP (1986)**          | Solves non-linear problems using hidden layers and backpropagation.          | Overfitting, requires manual feature engineering.                      | Classification, regression with structured data.   | CNNs for handling image data.                                                                                    |\n",
    "| **CNN (1998)**          | Excels in image processing, automatic spatial hierarchy detection.           | Struggles with sequential data, high computational needs.              | Image classification, object detection.            | Recurrent models (RNNs) for sequential data.                                                                     |\n",
    "| **RNN (1986)**          | Processes sequential data, maintains memory of previous inputs.              | Vanishing/exploding gradients, struggles with long dependencies.       | Time-series forecasting, NLP tasks.                | LSTM and GRU to handle long-term dependencies.                                                                   |\n",
    "| **LSTM (1997)**         | Handles long-term dependencies, reduces vanishing gradients.                 | Computationally expensive, requires careful tuning.                    | Machine translation, speech recognition.           | GRUs introduced simpler architectures with similar performance.                                                  |\n",
    "| **GRU (2014)**          | Simplified version of LSTM, fewer parameters, faster training.               | May underperform for complex tasks compared to LSTM.                   | Computational efficiency in sequential tasks.       | Attention-based models like Transformers.                                                                        |\n",
    "| **Transformers (2017)** | Handles long-range dependencies efficiently, parallel processing.            | High data and computational requirements.                              | NLP tasks, advanced image tasks (e.g., ViT).       | Specialized models like BERT, GPT.                                                                               |\n",
    "| **BERT (2018)**         | Bidirectional context understanding, effective for multiple NLP tasks.       | Resource-intensive fine-tuning, unsuitable for real-time applications. | Text classification, summarization, question answering. | GPT specialized in text generation and few-shot learning.                                                        |\n",
    "| **GPT (2018)**          | Excels in text generation, few-shot and zero-shot learning.                  | Requires extensive compute, prone to incorrect plausible content.      | Content creation, chatbots, story generation.       | Scaling models (GPT-2, GPT-3, GPT-4).                                                                            |\n",
    "| **Diffusion Models (2022)** | High-quality image generation, stable and controllable outputs.          | Slow inference, high computational resources.                          | Image generation, artistic designs, medical imaging. | Optimization for faster inference.                                                                               |\n",
    "| **ViT (2020)**          | Adapts Transformers for images, better on large-scale datasets.              | Requires more data than CNNs.                                          | Advanced image recognition tasks.                   | Hybrid CNN-ViT models, fine-tuning for smaller datasets.                                                         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9af54f-500d-49db-9b6d-c24e168ed550",
   "metadata": {},
   "source": [
    "\n",
    "### **1. General Evolution Themes**\n",
    "- **Neural Networks**:\n",
    "  - Began as biologically inspired but quickly diverged to purely mathematical models.\n",
    "  - Each new architecture focuses on solving a limitation of its predecessor (e.g., from linear separability to handling sequential data).\n",
    "\n",
    "- **Model Scaling**:\n",
    "  - Recent models like GPT-3 and GPT-4 focus on scaling parameters, datasets, and computational power.\n",
    "  - While scaling improves performance, it also raises concerns about accessibility and environmental impact.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Emerging Trends**\n",
    "- **Foundation Models**:\n",
    "  - Models like GPT, BERT, and DALL-E are pre-trained on massive datasets and then fine-tuned for specific tasks.\n",
    "  - They enable transfer learning, saving time and resources for downstream applications.\n",
    "\n",
    "- **Unified Architectures**:\n",
    "  - Research is moving toward models that handle both vision and language tasks (e.g., Flamingo, CLIP).\n",
    "  - The goal is to unify tasks that were traditionally solved by separate architectures.\n",
    "\n",
    "- **Efficient Models**:\n",
    "  - Lightweight architectures (e.g., MobileNet, DistilBERT) are designed for deployment on devices with limited resources like mobile phones.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Key Drawbacks to Note**\n",
    "- **Overfitting**:\n",
    "  - Most deep models are prone to overfitting on small datasets.\n",
    "  - Solutions include regularization techniques, data augmentation, and dropout layers.\n",
    "\n",
    "- **Data Requirements**:\n",
    "  - Deep learning models typically require large amounts of labeled data, which can be challenging to obtain in specialized fields like medical imaging.\n",
    "\n",
    "- **Interpretability**:\n",
    "  - Neural networks are often criticized as \"black boxes.\"\n",
    "  - Methods like SHAP and LIME help interpret models but are still an active area of research.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Decision-Making Tips**\n",
    "- **Task-Specific Models**:\n",
    "  - Use CNNs for image-related tasks but Transformers for text.\n",
    "  - For sequence-to-sequence tasks, start with RNNs or LSTMs but consider Transformers for state-of-the-art results.\n",
    "\n",
    "- **Data Availability**:\n",
    "  - If you have limited data, pre-trained models (like BERT or GPT) are ideal since they leverage transfer learning.\n",
    "\n",
    "- **Computational Resources**:\n",
    "  - Consider lightweight models for mobile applications or edge devices.\n",
    "  - Cloud-based GPUs or TPUs are essential for training large models like GPT.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Best Practices**\n",
    "- **Hyperparameter Tuning**:\n",
    "  - Always optimize learning rates, batch sizes, and architecture-specific parameters.\n",
    "- **Evaluation Metrics**:\n",
    "  - For text tasks, consider BLEU, ROUGE, or perplexity.\n",
    "  - For image tasks, use accuracy, IoU, or F1-score.\n",
    "- **Deployment**:\n",
    "  - Use frameworks like TensorFlow Lite or ONNX for efficient deployment of trained models.\n",
    "\n",
    "---\n",
    "\n",
    "### **Interesting Applications Across Models**\n",
    "- **CNNs in Medicine**: Early cancer detection using CNN-based models in histopathology images.\n",
    "- **Transformers in Finance**: Predicting stock trends using BERT for text analysis of market news.\n",
    "- **Diffusion Models in Art**: AI-generated art for creative industries using diffusion-based architectures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d17212-c29a-4b87-b520-ea92f30f2667",
   "metadata": {},
   "source": [
    "### **1. CNNs in Medicine**\n",
    "- **Example Use Case**: **Histopathology Image Analysis**\n",
    "  - CNNs have been employed to detect cancerous cells in histopathology images, significantly reducing the workload for radiologists.\n",
    "  - A model might classify an image into \"cancerous\" or \"non-cancerous\" based on patterns learned from previous scans.\n",
    "- **Techniques**:\n",
    "  - Transfer learning with pre-trained networks like ResNet or EfficientNet.\n",
    "  - Data augmentation to handle small datasets common in medical applications.\n",
    "- **Challenges**:\n",
    "  - Class imbalance: Cancerous images might be rarer than normal images.\n",
    "  - Interpretability: CNNs need to provide visual evidence (e.g., heatmaps using Grad-CAM).\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Transformers in Finance**\n",
    "- **Example Use Case**: **Sentiment Analysis for Stock Prediction**\n",
    "  - BERT models analyze financial news headlines to determine market sentiment.\n",
    "  - Positive sentiment might correlate with a stock price increase, while negative sentiment suggests a decrease.\n",
    "- **Techniques**:\n",
    "  - Fine-tuning BERT on financial datasets like news articles and earnings reports.\n",
    "  - Combining sentiment predictions with time-series models (e.g., ARIMA or LSTMs) for better predictions.\n",
    "- **Challenges**:\n",
    "  - Ambiguity in language: Financial texts can be subtle and context-specific.\n",
    "  - Noise in data: Not all news headlines impact stock prices.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Diffusion Models in Art**\n",
    "- **Example Use Case**: **AI-Generated Artwork**\n",
    "  - Diffusion models, like Stable Diffusion, iteratively add noise to images and learn to reverse the process.\n",
    "  - Artists use these models to create abstract designs or enhance creativity.\n",
    "- **Techniques**:\n",
    "  - Conditional diffusion to guide the output (e.g., generating a painting in the style of Van Gogh).\n",
    "  - Using text prompts for multimodal applications (e.g., \"A futuristic city at sunset\").\n",
    "- **Challenges**:\n",
    "  - Computational cost: Inference is slow and requires significant GPU power.\n",
    "  - Ethical concerns: Plagiarism risks when replicating artistic styles.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. RNNs and LSTMs in Healthcare**\n",
    "- **Example Use Case**: **Electronic Health Record (EHR) Analysis**\n",
    "  - Sequential models like LSTMs analyze patient histories to predict potential illnesses.\n",
    "  - For instance, predicting a heart attack risk based on historical data like cholesterol levels and ECG readings.\n",
    "- **Techniques**:\n",
    "  - Embedding categorical data (e.g., disease codes) and feeding it into the LSTM.\n",
    "  - Attention mechanisms for emphasizing critical parts of the sequence.\n",
    "- **Challenges**:\n",
    "  - Missing data: EHRs often have incomplete entries.\n",
    "  - Scalability: Large hospitals generate terabytes of sequential data.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Lightweight Models**\n",
    "- **Example Use Case**: **Mobile Applications**\n",
    "  - MobileNets are used for real-time object detection in mobile apps like Snapchat or Instagram.\n",
    "  - Applications include AR filters, live translations, and personal assistants.\n",
    "- **Techniques**:\n",
    "  - Quantization to reduce model size.\n",
    "  - Knowledge distillation to transfer knowledge from a large model to a smaller one.\n",
    "- **Challenges**:\n",
    "  - Trade-off between accuracy and latency.\n",
    "  - Hardware-specific optimizations might be necessary.\n",
    "\n",
    "---\n",
    "\n",
    "### **Common Practical Tips**\n",
    "1. **Explainability Tools**:\n",
    "   - Use tools like **SHAP** or **LIME** to explain black-box models.\n",
    "   - For CNNs, visualize feature maps to understand what the model \"sees.\"\n",
    "2. **Regularization Techniques**:\n",
    "   - Dropout, weight decay, and data augmentation can prevent overfitting.\n",
    "3. **Hyperparameter Optimization**:\n",
    "   - Use tools like Optuna or GridSearchCV for fine-tuning critical parameters.\n",
    "4. **Cloud and Hardware**:\n",
    "   - Leverage GPUs or TPUs for faster training of large models.\n",
    "   - For on-device inference, optimize models using TensorFlow Lite or ONNX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e21fe0b-1caa-4021-aa0e-fe4aeb7a5e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from tensorflow.python.training.tracking import data_structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1558d2c1-80eb-4e82-ab43-c14dca24d26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = hub.KerasLayer(\"https://kaggle.com/models/tensorflow/bert/TensorFlow2/en-uncased-preprocess/3\")\n",
    "encoder = (\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48d41e88-60c8-4df1-bbad-2c34ee7adf5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_mask', 'input_type_ids', 'input_word_ids'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_test = ['nice movie', 'i dont love']\n",
    "text_preprocessor = preprocessor(text_test)\n",
    "text_preprocessor.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f206d2be-44fd-418b-946e-0618c747159d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessor['input_mask']\n",
    "#ClS nice movie SEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "391bcacb-04cf-4299-8cc0-2e7a479dd732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessor['input_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "634fcd87-8d97-41c0-afbf-014f04366e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
       "array([[ 101, 3835, 3185,  102,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0],\n",
       "       [ 101, 1045, 2123, 2102, 2293,  102,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0]])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessor['input_word_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "979e3341-8f04-4cb5-ac4d-26ec60956d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['default', 'encoder_outputs', 'pooled_output', 'sequence_output'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model = hub.KerasLayer(encoder)\n",
    "bert_result = bert_model(text_preprocessor)\n",
    "bert_result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb5179ba-72c4-442d-bbcb-be7968f8e0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\n",
       "array([[-0.82307976, -0.33021632,  0.05804335, ...,  0.15002407,\n",
       "        -0.5304848 ,  0.84959537],\n",
       "       [-0.9289333 , -0.51373696, -0.9104153 , ..., -0.68788904,\n",
       "        -0.7519929 ,  0.9477711 ]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_result['pooled_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b3a76d2-8c2b-4a13-94ac-dc4aae3f6e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
       "array([[[-0.04972774, -0.16134027, -0.0449734 , ..., -0.19434878,\n",
       "          0.15166706,  0.07051323],\n",
       "        [ 0.40138033, -0.71619904,  0.7960528 , ..., -0.34071213,\n",
       "          0.01467809, -0.282048  ],\n",
       "        [ 0.15849896, -0.13599616, -0.31225622, ..., -0.31121084,\n",
       "         -0.10993739, -0.5535932 ],\n",
       "        ...,\n",
       "        [-0.07264662, -0.2278554 ,  0.50889313, ..., -0.02908365,\n",
       "          0.10880288,  0.17614342],\n",
       "        [-0.35652015, -0.61217856,  0.10107186, ...,  0.1591494 ,\n",
       "          0.01639703, -0.17355028],\n",
       "        [-0.0866785 , -0.28234932,  0.47228336, ...,  0.03270615,\n",
       "          0.10365032,  0.07470024]],\n",
       "\n",
       "       [[-0.37575817,  0.59689146, -0.4135615 , ..., -0.51438975,\n",
       "          0.4503662 ,  0.61310536],\n",
       "        [-0.22726893,  0.6257317 , -0.00740789, ..., -0.16128698,\n",
       "          0.39208385,  0.7126612 ],\n",
       "        [ 0.09385063,  0.762618  ,  0.32807058, ..., -0.4738144 ,\n",
       "          0.47743925,  0.163544  ],\n",
       "        ...,\n",
       "        [-0.15055081,  0.30510733,  0.52018976, ..., -0.13480574,\n",
       "          0.08415237,  0.6181773 ],\n",
       "        [ 0.01068032,  0.16230659,  0.63364947, ..., -0.03628787,\n",
       "          0.11733729,  0.40605962],\n",
       "        [-0.09910639,  0.22269239,  0.6096647 , ..., -0.14310603,\n",
       "          0.07811102,  0.5070975 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_result['sequence_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0edb2d-a68f-4b40-b81a-cbec26c83104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
